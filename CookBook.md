## -------------------------------------------------------------------------------------------##
## ----------------------Week 3 Project - Getting and Cleaning Data---------------------------##
## ---------------------------------Code Book-Run Book----------------------------------------##
## -------------------------------------------------------------------------------------------##
## ---------------------------------By E.A. 6/19/2015-----------------------------------------##
## -------------------------------------------------------------------------------------------##

## Project Description
This project is an assigment from the Coursera class Getting and Cleaning Data given on Week 3. The objective is to apply R concepts to 
building a tidy dataset.
The steps that we were asked to follow to create the tidy datasets are:
 1) Merges the training and the test sets to create one data set.
 2) Extracts only the measurements on the mean and standard deviation for each measurement. 
 3) Uses descriptive activity names to name the activities in the data set
 4) Appropriately labels the data set with descriptive variable names. 
 5) From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

## Notes about the original data
We are working with a dataset that was been generated by capturing the data generated by accelerometer 
and gyroscope embedded into a Samsung Galaxy SII watch that was wore by test subjects while they were
performing some specific exercises (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
More details about the how and what can be found at http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
The original dataset can be downloaded at:https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

## Guide to create the tidy datasets
We were asked to create two tiday data sets:
**First dataset (output of all the steps up to 4) ):
1) Extract the needed data that includes the test and train data, their corresponding row labels, the feature list and the description of the activities
2) We start by binding the test and training datasets from which we keep only the variable that deal with mean or standard deviation
3) Both the activity label id data set and the dataset created in 2) have the same column header. Then prior to binding these two datasets we make sure to rename the column headers of the activity label id dataset.
4) We can now bind the labels ids of the test and training sets.
5) We then enrich the dataset of 4) by adding the description of the activity labels.
4) After rearanging the order of the variables to have consecutively the activity label id and then activity label description, we finally change the column header of the variables to reflect their actual description (feature description).

**Second dataset (output of the step 5) which is included in this GitHub:
1) For this dataset we first extract and then merge the datasets containing the list of the test subjects of the test and train data.
2) We then bind this dataset to the one that was the output of the first dataset which steps where described above.
3) We then create the final dataset that will contain the average for all the variable of the first dataset above by activity and subject.
4) The final step is to rename the columns variable to show that they are now averages.

##Description of the variables in the final_X.txt file
This file include in this GitHub contains means of features outcome of measuring the lineare and angular accelleration of the Samsung Galaxi SII that was wear by test subjects that were doing the six activities described above in this document. The description of this dataset is as follow:
 - Dimensions of the dataset: 180 observations and 80 variables
 - Summary of the data: the 180 observations correspond to the 30 subjects that are performing the 6 activities. The 80 variables are two descriptive variables are act_desc and subjects which respectively correspond to the activity and the id of the subjects that performed these activities, and 78 metrics variables that contains the average of the different features.
 - Variables present in the dataset are the following:
 $ VARIABLE NAME                     : CLASS    
 $ act_desc                          : Factor w/ 6 levels WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING
 $ subjects                          : int
 $ avg_tBodyAcc-mean()-X             : num
 $ avg_tBodyAcc-mean()-Y             : num
 $ avg_tBodyAcc-mean()-Z             : num
 $ avg_tBodyAcc-std()-X              : num
 $ avg_tBodyAcc-std()-Y              : num
 $ avg_tBodyAcc-std()-Z              : num
 $ avg_tGravityAcc-mean()-X          : num
 $ avg_tGravityAcc-mean()-Y          : num
 $ avg_tGravityAcc-mean()-Z          : num
 $ avg_tGravityAcc-std()-X           : num
 $ avg_tGravityAcc-std()-Y           : num
 $ avg_tGravityAcc-std()-Z           : num
 $ avg_tBodyAccJerk-mean()-X         : num
 $ avg_tBodyAccJerk-mean()-Y         : num
 $ avg_tBodyAccJerk-mean()-Z         : num
 $ avg_tBodyAccJerk-std()-X          : num
 $ avg_tBodyAccJerk-std()-Y          : num
 $ avg_tBodyAccJerk-std()-Z          : num
 $ avg_tBodyGyro-mean()-X            : num
 $ avg_tBodyGyro-mean()-Y            : num
 $ avg_tBodyGyro-mean()-Z            : num
 $ avg_tBodyGyro-std()-X             : num
 $ avg_tBodyGyro-std()-Y             : num
 $ avg_tBodyGyro-std()-Z             : num
 $ avg_tBodyGyroJerk-mean()-X        : num
 $ avg_tBodyGyroJerk-mean()-Y        : num
 $ avg_tBodyGyroJerk-mean()-Z        : num
 $ avg_tBodyGyroJerk-std()-X         : num
 $ avg_tBodyGyroJerk-std()-Y         : num
 $ avg_tBodyGyroJerk-std()-Z         : num
 $ avg_tBodyAccMag-mean()            : num
 $ avg_tBodyAccMag-std()             : num
 $ avg_tGravityAccMag-mean()         : num
 $ avg_tGravityAccMag-std()          : num
 $ avg_tBodyAccJerkMag-mean()        : num
 $ avg_tBodyAccJerkMag-std()         : num
 $ avg_tBodyGyroMag-mean()           : num
 $ avg_tBodyGyroMag-std()            : num
 $ avg_tBodyGyroJerkMag-mean()       : num
 $ avg_tBodyGyroJerkMag-std()        : num
 $ avg_fBodyAcc-mean()-X             : num
 $ avg_fBodyAcc-mean()-Y             : num
 $ avg_fBodyAcc-mean()-Z             : num
 $ avg_fBodyAcc-std()-X              : num
 $ avg_fBodyAcc-std()-Y              : num
 $ avg_fBodyAcc-std()-Z              : num
 $ avg_fBodyAcc-meanFreq()-X         : num
 $ avg_fBodyAcc-meanFreq()-Y         : num
 $ avg_fBodyAcc-meanFreq()-Z         : num
 $ avg_fBodyAccJerk-mean()-X         : num
 $ avg_fBodyAccJerk-mean()-Y         : num
 $ avg_fBodyAccJerk-mean()-Z         : num
 $ avg_fBodyAccJerk-std()-X          : num
 $ avg_fBodyAccJerk-std()-Y          : num
 $ avg_fBodyAccJerk-std()-Z          : num
 $ avg_fBodyAccJerk-meanFreq()-X     : num
 $ avg_fBodyAccJerk-meanFreq()-Y     : num
 $ avg_fBodyAccJerk-meanFreq()-Z     : num
 $ avg_fBodyGyro-mean()-X            : num
 $ avg_fBodyGyro-mean()-Y            : num
 $ avg_fBodyGyro-mean()-Z            : num
 $ avg_fBodyGyro-std()-X             : num
 $ avg_fBodyGyro-std()-Y             : num
 $ avg_fBodyGyro-std()-Z             : num
 $ avg_fBodyGyro-meanFreq()-X        : num
 $ avg_fBodyGyro-meanFreq()-Y        : num
 $ avg_fBodyGyro-meanFreq()-Z        : num
 $ avg_fBodyAccMag-mean()            : num
 $ avg_fBodyAccMag-std()             : num
 $ avg_fBodyAccMag-meanFreq()        : num
 $ avg_fBodyBodyAccJerkMag-mean()    : num
 $ avg_fBodyBodyAccJerkMag-std()     : num
 $ avg_fBodyBodyAccJerkMag-meanFreq(): num
 $ avg_fBodyBodyGyroMag-mean()       : num
 $ avg_fBodyBodyGyroMag-std()        : num
 $ avg_fBodyBodyGyroMag-meanFreq()   : num
 $ avg_fBodyBodyGyroJerkMag-mean()   : num
 $ avg_fBodyBodyGyroJerkMag-std()    : num
 
 ##Sources
http://www.r-project.org/
https://class.coursera.org/getdata-004/human_grading/view/courses/972137/assessments/3/submissions
Regular Expressions: http://regexr.com/
Joins with dplyr: https://stat545-ubc.github.io/bit001_dplyr-cheatsheet.html
Create the mean for all the 78 columns at once: http://stackoverflow.com/questions/22644804/how-can-i-use-dplyr-to-apply-a-function-to-all-non-group-by-columns